{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jPFTbreT4ghW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "try:\n",
        "  cv2.imshow()\n",
        "  show=cv2.imshow\n",
        "except:\n",
        "  from google.colab.patches import cv2_imshow as show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KVBi8XM3wA64"
      },
      "outputs": [],
      "source": [
        "pxls=100\n",
        "blackPxls=0.5\n",
        "th=90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QLIKwnGYhIo2"
      },
      "outputs": [],
      "source": [
        "def preprocess(img):\n",
        "  img=np.array(img,np.int32)\n",
        "  shp=(400,400)\n",
        "  for r in range(shp[0]):\n",
        "    for c in range((img.shape[1])):\n",
        "      if r ==0 and c==0:\n",
        "        img[r][c]=img[r][c]>th\n",
        "      elif r==0 and c:\n",
        "        img[r][c]=img[r][c-1]+(img[r][c]>th)\n",
        "      elif c==0 and r:\n",
        "        img[r][c]=img[r-1][c]+(img[r][c]>th)\n",
        "      else:\n",
        "        img[r][c]=img[r-1][c]+img[r][c-1]-img[r-1][c-1]+(img[r][c]>th)\n",
        "  for r in range(shp[0],img.shape[0]):\n",
        "    for c in range((shp[1])):\n",
        "      if r ==0 and c==0:\n",
        "        img[r][c]=img[r][c]>th\n",
        "      elif r==0 and c:\n",
        "        img[r][c]=img[r][c-1]+(img[r][c]>th)\n",
        "      elif c==0 and r:\n",
        "        img[r][c]=img[r-1][c]+(img[r][c]>th)\n",
        "      else:\n",
        "        img[r][c]=img[r-1][c]+img[r][c-1]-img[r-1][c-1]+(img[r][c]>th)\n",
        "  return img\n",
        "def ratioBlack(img,r,c,h,w):\n",
        "  h-=1\n",
        "  w-=1\n",
        "  sm=0\n",
        "  if r ==0 and c==0:\n",
        "    sm= img[h][w]\n",
        "  elif r==0 and c:\n",
        "    sm= img[h][c+w]- img[h][c-1]\n",
        "  elif c==0 and r:\n",
        "    sm= img[r+h][w]-img[r-1][w]\n",
        "  else:\n",
        "    sm= img[r+h][c+w]-img[r-1][c+w]-img[r+h][c-1]+img[r-1][c-1]\n",
        "  total=((h+1)*(w+1))\n",
        "  return 1-sm/total;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MiKcS9XYqIvt"
      },
      "outputs": [],
      "source": [
        "def convoluteShort(on,kernelShape):\n",
        "  \n",
        "  if on.shape[0]<200 or on.shape[1]<200:\n",
        "    return 1\n",
        "\n",
        "  y_len=kernelShape[0]\n",
        "  x_len=kernelShape[1]\n",
        "  y_from,x_from=0,0\n",
        "  done=False\n",
        "  for y in range(100):\n",
        "    for x in range(100):\n",
        "      res=ratioBlack(on,y,x,y_len,x_len)\n",
        "      if res>blackPxls:\n",
        "        y_from,x_from=(y+y_len,x+x_len)\n",
        "        done=True\n",
        "        break\n",
        "    if done:\n",
        "      break\n",
        "\n",
        "  # try:\n",
        "  while(ratioBlack(on,y_from,x_from,5,5)>blackPxls):\n",
        "    x_from+=2\n",
        "  x_from-=2\n",
        "  while(1-ratioBlack(on,y_from,x_from,2,pxls)>blackPxls):\n",
        "    y_from+=1\n",
        "  return y_from,x_from\n",
        "  # except:\n",
        "  #   return 2\n",
        "\n",
        "\n",
        "def nextHorizontalShort(on,y_prev,x_prev):\n",
        "  y_prev+=30\n",
        "  y_from=y_prev\n",
        "  x_from=x_prev\n",
        "  while(ratioBlack(on,y_from,x_from,5,pxls)>blackPxls):\n",
        "      y_from+=1\n",
        "  while(1-ratioBlack(on,y_from,x_from,5,pxls)>blackPxls):\n",
        "      y_from+=1\n",
        "  return y_from,x_from\n",
        "\n",
        "def nextVerticalShort(on,y_prev,x_prev):\n",
        "  x_prev+=30\n",
        "  y_from=y_prev\n",
        "  x_from=x_prev\n",
        "  while(ratioBlack(on,y_from,x_from,pxls,5)>blackPxls):\n",
        "    x_from+=1\n",
        "  while(1-ratioBlack(on,y_from,x_from,pxls,5)>blackPxls):\n",
        "      x_from+=1\n",
        "  return y_from,x_from"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tNPe7zwBF55o"
      },
      "outputs": [],
      "source": [
        "def rotate(img,angle):\n",
        "  rows = img.shape[0]\n",
        "  cols = img.shape[1]\n",
        "\n",
        "  img_center = (cols / 2, rows / 2)\n",
        "  M = cv2.getRotationMatrix2D(img_center, angle, 1)\n",
        "\n",
        "  rotated_image = cv2.warpAffine(img, M, (cols, rows),\n",
        "                            borderMode=cv2.BORDER_CONSTANT,\n",
        "                            borderValue=(255,255,255))\n",
        "  return rotated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m-bVXxqXaQAA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cE8WsKHVnV8o"
      },
      "outputs": [],
      "source": [
        "def getAllCells(hori,ver,on):\n",
        "  starts=[]\n",
        "  for y in range(len(hori)-1):\n",
        "    for x in range(len(ver)-1):\n",
        "      leftTop=hori[y][0],ver[x][1]\n",
        "      rightEnd=hori[y+1][0],ver[x+1][1]\n",
        "      starts.append((leftTop,rightEnd))\n",
        "  return starts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gV0cT6KMIxRq"
      },
      "outputs": [],
      "source": [
        "def giveHoriVer(marked):\n",
        "  for ii in np.arange(0,5):\n",
        "      for i in [ii,-(ii)]:\n",
        "        global done\n",
        "        done=False\n",
        "        if i:\n",
        "          timg=rotate(marked,i)\n",
        "        else: \n",
        "          timg=marked\n",
        "        img=preprocess(timg)\n",
        "        try:\n",
        "          leftEndpoint=convoluteShort(img,(30,30))\n",
        "          horizontal=[leftEndpoint]\n",
        "          vertical=[leftEndpoint]\n",
        "          while(len(horizontal)<10):\n",
        "            horizontal.append(nextHorizontalShort(img,horizontal[-1][0],horizontal[-1][1]))\n",
        "          while(len(vertical)<8):\n",
        "            vertical.append(nextVerticalShort(img,vertical[-1][0],vertical[-1][1]))\n",
        "          done=True\n",
        "          marked=timg\n",
        "          break\n",
        "        except:\n",
        "          if ii==0:\n",
        "            break\n",
        "      if done :\n",
        "        break\n",
        "  # print(done)\n",
        "  if not done:\n",
        "    raise \"not good image\"\n",
        "  else:\n",
        "    return horizontal,vertical,marked"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(100,100)\n",
        "num_classes=3"
      ],
      "metadata": {
        "id": "ffop9zFzft2N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ApCo7dU2uIKL"
      },
      "outputs": [],
      "source": [
        "def extractImg(img,x1,y1,x2,y2):\n",
        "  x1=x1-10\n",
        "  y1=y1-10\n",
        "  x2=x2+10\n",
        "  y2=y2+10\n",
        "  trimmed=img[y1:y2,x1:x2,np.newaxis]\n",
        "  trimmed=tf.image.resize([trimmed],input_shape)\n",
        "  return trimmed[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YNsWb7RWLkx0"
      },
      "outputs": [],
      "source": [
        "def getSubImgs(marked):\n",
        "  horizontal,vertical,marked=giveHoriVer(marked)\n",
        "  allBlocks=getAllCells(horizontal,vertical,marked)\n",
        "  cells=marked.copy()\n",
        "  subImgs=[]\n",
        "  for lt,rb in allBlocks:\n",
        "    cv2.rectangle(cells,lt[::-1],rb[::-1],100,2)\n",
        "    subImgs.append(extractImg(marked,lt[1],lt[0],rb[1],rb[0]))\n",
        "  subImgs=tf.convert_to_tensor(subImgs)\n",
        "  return subImgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1ACvTcAWSEdF"
      },
      "outputs": [],
      "source": [
        "def readImgGray(filename):\n",
        "  imgGrid=cv2.imread(filename,cv2.IMREAD_GRAYSCALE)\n",
        "  return cv2.resize(imgGrid,(600,800),interpolation=cv2.INTER_AREA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xqpv-ATJgVkC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer,Flatten,Dropout,Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
        "from tensorflow.keras import layers, models, Model, optimizers\n",
        "from sklearn.model_selection import train_test_split as tts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rozsI1hHZ9TF"
      },
      "outputs": [],
      "source": [
        "cellStates=['empty','present','absent']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def createData(imgName,stt):\n",
        "  subImgs=[]\n",
        "  states=[]\n",
        "  assert len(imgName)==len(stt)\n",
        "  for f,s in zip(imgName,stt):\n",
        "    si=getSubImgs(readImgGray(f))\n",
        "    sos=tf.constant(si.shape[0]*[s],tf.uint8)\n",
        "    subImgs.extend(si)\n",
        "    states.extend(sos)\n",
        "  return subImgs,states"
      ],
      "metadata": {
        "id": "I-kuNyyHlM8W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subImgs,states=createData([\"grid.png\",\"handA.png\",\"handP.png\",\"excel.png\",\"excelA.png\",\"priyaA.jpeg\",\"priyaP.jpeg\"],[0,2,1,1,2,2,1])"
      ],
      "metadata": {
        "id": "coMpEWb6mD6O"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer,Conv2D,BatchNormalization,Activation,AveragePooling2D,Dense,MaxPooling2D"
      ],
      "metadata": {
        "id": "RyqQQAMNdwRg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(X, num_filters: int, stride: int = 1, kernel_size: int = 3,\n",
        "                   activation: str = 'relu', bn: bool = True, conv_first: bool = True):\n",
        "    conv_layer = Conv2D(num_filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        strides=stride,\n",
        "                        padding='same')\n",
        "    # X = input\n",
        "    if conv_first:\n",
        "        X = conv_layer(X)\n",
        "        if bn:\n",
        "            X = BatchNormalization()(X)\n",
        "        if activation is not None:\n",
        "            X = Activation(activation)(X)\n",
        "            X = Dropout(0.2)(X)\n",
        "    else:\n",
        "        if bn:\n",
        "            X = BatchNormalization()(X)\n",
        "        if activation is not None:\n",
        "            X = Activation(activation)(X)\n",
        "        X = conv_layer(X)\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "DseIha-3dlYI"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_filters_in = 25\n",
        "num_res_block=5\n",
        "inputs = keras.Input(shape=input_shape+(1,))\n",
        "X=Conv2D(num_filters_in,kernel_size=3,name=\"first_Conv\")(inputs)\n",
        "X=BatchNormalization()(X)\n",
        "X=Activation('relu')(X)\n",
        "X=MaxPooling2D()(X)\n",
        "# ResNet V2 performs Conv2D on X before spiting into two path\n",
        "X = residual_block(X=X, num_filters=num_filters_in, conv_first=False)\n",
        "\n",
        "# Building stack of residual units\n",
        "for stage in range(2):\n",
        "    for unit_res_block in range(num_res_block):\n",
        "        activation = 'relu'\n",
        "        bn = True\n",
        "        stride = 1\n",
        "        # First layer and first stage\n",
        "        if stage == 0:\n",
        "            num_filters_out = num_filters_in * 4\n",
        "            if unit_res_block == 0:\n",
        "                activation = None\n",
        "                bn = False\n",
        "            # First layer but not first stage\n",
        "        else:\n",
        "            num_filters_out = num_filters_in * 2\n",
        "            if unit_res_block == 0:\n",
        "                stride = 2\n",
        "\n",
        "        # bottleneck residual unit\n",
        "        y = residual_block(X,\n",
        "                           num_filters=num_filters_in,\n",
        "                           kernel_size=1,\n",
        "                           stride=stride,\n",
        "                           activation=activation,\n",
        "                           bn=bn,\n",
        "                           conv_first=False)\n",
        "        y = residual_block(y,\n",
        "                           num_filters=num_filters_in,\n",
        "                           conv_first=False)\n",
        "        y = residual_block(y,\n",
        "                           num_filters=num_filters_out,\n",
        "                           kernel_size=1,\n",
        "                           conv_first=False)\n",
        "        if unit_res_block == 0:\n",
        "            # linear projection residual shortcut connection to match\n",
        "            # changed dims\n",
        "            X = residual_block(X=X,\n",
        "                               num_filters=num_filters_out,\n",
        "                               kernel_size=1,\n",
        "                               stride=stride,\n",
        "                               activation=None,\n",
        "                               bn=False)\n",
        "        X = tf.keras.layers.add([X, y])\n",
        "    num_filters_in = num_filters_out\n",
        "X = BatchNormalization()(X)\n",
        "X = Activation('relu')(X)\n",
        "X = AveragePooling2D(pool_size=8)(X)\n",
        "y = Flatten()(X)\n",
        "y = Dense(512, activation='relu')(y)\n",
        "y = BatchNormalization()(y)\n",
        "y = Dropout(0.5)(y)\n",
        "# y = Dense(512, activation='relu')(y)\n",
        "# y = BatchNormalization()(y)\n",
        "# y = Dropout(0.5)(y)\n",
        "outputs = Dense(num_classes,\n",
        "                activation='softmax')(y)\n"
      ],
      "metadata": {
        "id": "kGIEC53PmcyI"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "90t_CIfJ3lO9"
      },
      "outputs": [],
      "source": [
        "def giveModel():\n",
        "  return Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "ukKwtrpfApHh"
      },
      "outputs": [],
      "source": [
        "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n",
        "checkpoint = ModelCheckpoint('vgg16_finetune.h15', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "_PTqeU5Oaccz"
      },
      "outputs": [],
      "source": [
        "def createDataSet(X,y,is_training=False):\n",
        "  ds=tf.data.Dataset.from_tensor_slices((X,y))\n",
        "  ds=ds.batch(32).prefetch(32)\n",
        "  if is_training:\n",
        "    ds=ds.shuffle(32)\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "CsaicnN7fNDw"
      },
      "outputs": [],
      "source": [
        "X=np.array(subImgs)\n",
        "y=np.array(states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "iLqo64-8glAx"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test=tts(X,y,test_size=0.25,random_state=42,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "xaXsJO7-jepE"
      },
      "outputs": [],
      "source": [
        "train_ds=createDataSet(X_train,y_train,True)\n",
        "val_ds=createDataSet(X_test,y_test,True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Attendance_model=giveModel()\n",
        "# keras.utils.plot_model(Attendance_model)\n",
        "# Attendance_model.summary()"
      ],
      "metadata": {
        "id": "z6pJi-lFkkZq"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "dKakxFqSA01b"
      },
      "outputs": [],
      "source": [
        "learning_rate= 5e-5\n",
        "Attendance_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizers.Adam(learning_rate=learning_rate), metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQPtSkh8BLlS"
      },
      "outputs": [],
      "source": [
        "# with tf.device(\"/GPU:0\"):\n",
        "history = Attendance_model.fit(train_ds, epochs=50,validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "SeuM3VNOnQvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdda124e-0d2b-402f-9499-6e1ae9b798b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 2s 93ms/step - loss: 0.2140 - accuracy: 0.9279\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21400712430477142, 0.9279279112815857]"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ],
      "source": [
        "Attendance_model.evaluate(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def imgWithLabel(img,model,labels):\n",
        "  pred=tf.argmax(model.predict(np.array([img])),axis=1)[0].numpy()\n",
        "  try:\n",
        "    img=tf.image.grayscale_to_rgb(img)\n",
        "    image = cv2.putText(img.numpy(), labels[pred], (20,20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0),  2, cv2.LINE_AA)\n",
        "  except:\n",
        "    image = cv2.putText(img, labels[pred], (20,20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0),  2, cv2.LINE_AA)\n",
        "  return image"
      ],
      "metadata": {
        "id": "2wJCtjMHtSW8"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subImgs,states=createData([\"grid.png\",\"priyaA.jpeg\",\"priyaP.jpeg\"],[0,2,1])\n",
        "for i in subImgs:\n",
        "  display(show(imgWithLabel(i,Attendance_model,cellStates)))"
      ],
      "metadata": {
        "id": "hivVfj4IuZAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Attendance_model.save(\"resConv4GridModel\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbKKQN6rKwn1",
        "outputId": "5c48411a-064a-47c9-9470-e7622ce25bda"
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: resConv4GridModel/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.models.load_model(\"resConv4GridModel\")"
      ],
      "metadata": {
        "id": "-T-qezuKOrxQ"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -h resConv4GridModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxlUjxIcP3d2",
        "outputId": "49d87846-43a8-4a69-a82c-ac190020cbec"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20M\tresConv4GridModel/variables\n",
            "4.0K\tresConv4GridModel/assets\n",
            "22M\tresConv4GridModel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r resConv4GridModel.zip resConv4GridModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QUbk_HuQQLK",
        "outputId": "1cc20a9e-d82b-4cae-d264-ef928ba14cf2"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: resConv4GridModel/ (stored 0%)\n",
            "updating: resConv4GridModel/variables/ (stored 0%)\n",
            "updating: resConv4GridModel/variables/variables.index (deflated 80%)\n",
            "updating: resConv4GridModel/variables/variables.data-00000-of-00001 (deflated 10%)\n",
            "updating: resConv4GridModel/keras_metadata.pb (deflated 95%)\n",
            "updating: resConv4GridModel/saved_model.pb (deflated 92%)\n",
            "updating: resConv4GridModel/assets/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model)"
      ],
      "metadata": {
        "id": "-OPO9MPKQemv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tLE4HjsxRlNw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Blocks_training-gpu.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}