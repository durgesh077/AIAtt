{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "jPFTbreT4ghW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "try:\n",
        "  cv2.imshow()\n",
        "  show=cv2.imshow\n",
        "except:\n",
        "  from google.colab.patches import cv2_imshow as show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "KVBi8XM3wA64"
      },
      "outputs": [],
      "source": [
        "pxls=100\n",
        "blackPxls=0.5\n",
        "th=90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "QLIKwnGYhIo2"
      },
      "outputs": [],
      "source": [
        "def preprocess(img):\n",
        "  img=np.array(img,np.int32)\n",
        "  shp=(250,150)\n",
        "  for r in range(shp[0]):\n",
        "    for c in range((img.shape[1])):\n",
        "      if r ==0 and c==0:\n",
        "        img[r][c]=img[r][c]>th\n",
        "      elif r==0 and c:\n",
        "        img[r][c]=img[r][c-1]+(img[r][c]>th)\n",
        "      elif c==0 and r:\n",
        "        img[r][c]=img[r-1][c]+(img[r][c]>th)\n",
        "      else:\n",
        "        img[r][c]=img[r-1][c]+img[r][c-1]-img[r-1][c-1]+(img[r][c]>th)\n",
        "  for r in range(shp[0],img.shape[0]):\n",
        "    for c in range((shp[1])):\n",
        "      if r ==0 and c==0:\n",
        "        img[r][c]=img[r][c]>th\n",
        "      elif r==0 and c:\n",
        "        img[r][c]=img[r][c-1]+(img[r][c]>th)\n",
        "      elif c==0 and r:\n",
        "        img[r][c]=img[r-1][c]+(img[r][c]>th)\n",
        "      else:\n",
        "        img[r][c]=img[r-1][c]+img[r][c-1]-img[r-1][c-1]+(img[r][c]>th)\n",
        "  return img\n",
        "def ratioBlack(img,r,c,h,w):\n",
        "  h-=1\n",
        "  w-=1\n",
        "  sm=0\n",
        "  if r ==0 and c==0:\n",
        "    sm= img[h][w]\n",
        "  elif r==0 and c:\n",
        "    sm= img[h][c+w]- img[h][c-1]\n",
        "  elif c==0 and r:\n",
        "    sm= img[r+h][w]-img[r-1][w]\n",
        "  else:\n",
        "    sm= img[r+h][c+w]-img[r-1][c+w]-img[r+h][c-1]+img[r-1][c-1]\n",
        "  total=((h+1)*(w+1))\n",
        "  return 1-sm/total;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "MiKcS9XYqIvt"
      },
      "outputs": [],
      "source": [
        "def convoluteShort(on,kernelShape):\n",
        "  \n",
        "  if on.shape[0]<200 or on.shape[1]<200:\n",
        "    return 1\n",
        "\n",
        "  y_len=kernelShape[0]\n",
        "  x_len=kernelShape[1]\n",
        "  y_from,x_from=0,0\n",
        "  done=False\n",
        "  for y in range(100):\n",
        "    for x in range(100):\n",
        "      res=ratioBlack(on,y,x,y_len,x_len)\n",
        "      if res>blackPxls:\n",
        "        y_from,x_from=(y+y_len,x+x_len)\n",
        "        done=True\n",
        "        break\n",
        "    if done:\n",
        "      break\n",
        "\n",
        "  # try:\n",
        "  while(ratioBlack(on,y_from,x_from,5,5)>blackPxls):\n",
        "    x_from+=2\n",
        "  x_from-=2\n",
        "  while(1-ratioBlack(on,y_from,x_from,2,pxls)>blackPxls):\n",
        "    y_from+=1\n",
        "  return y_from,x_from\n",
        "  # except:\n",
        "  #   return 2\n",
        "\n",
        "\n",
        "def nextHorizontalShort(on,y_prev,x_prev):\n",
        "  y_prev+=30\n",
        "  y_from=y_prev\n",
        "  x_from=x_prev\n",
        "  while(ratioBlack(on,y_from,x_from,5,pxls)>blackPxls):\n",
        "      y_from+=1\n",
        "  while(1-ratioBlack(on,y_from,x_from,5,pxls)>blackPxls):\n",
        "      y_from+=1\n",
        "  return y_from,x_from\n",
        "\n",
        "def nextVerticalShort(on,y_prev,x_prev):\n",
        "  x_prev+=30\n",
        "  y_from=y_prev\n",
        "  x_from=x_prev\n",
        "  while(ratioBlack(on,y_from,x_from,pxls,5)>blackPxls):\n",
        "    x_from+=1\n",
        "  while(1-ratioBlack(on,y_from,x_from,pxls,5)>blackPxls):\n",
        "      x_from+=1\n",
        "  return y_from,x_from"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "tNPe7zwBF55o"
      },
      "outputs": [],
      "source": [
        "def rotate(img,angle):\n",
        "  rows = img.shape[0]\n",
        "  cols = img.shape[1]\n",
        "\n",
        "  img_center = (cols / 2, rows / 2)\n",
        "  M = cv2.getRotationMatrix2D(img_center, angle, 1)\n",
        "\n",
        "  rotated_image = cv2.warpAffine(img, M, (cols, rows),\n",
        "                            borderMode=cv2.BORDER_CONSTANT,\n",
        "                            borderValue=(255,255,255))\n",
        "  return rotated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "m-bVXxqXaQAA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "cE8WsKHVnV8o"
      },
      "outputs": [],
      "source": [
        "def getAllCells(hori,ver,on):\n",
        "  starts=[]\n",
        "  for y in range(len(hori)-1):\n",
        "    for x in range(len(ver)-1):\n",
        "      leftTop=hori[y][0],ver[x][1]\n",
        "      rightEnd=hori[y+1][0],ver[x+1][1]\n",
        "      starts.append((leftTop,rightEnd))\n",
        "  return starts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "gV0cT6KMIxRq"
      },
      "outputs": [],
      "source": [
        "def giveHoriVer(marked):\n",
        "  for ii in np.arange(0,5):\n",
        "      for i in [ii,-(ii)]:\n",
        "        global done\n",
        "        done=False\n",
        "        if i:\n",
        "          timg=rotate(marked,i)\n",
        "        else: \n",
        "          timg=marked\n",
        "        img=preprocess(timg)\n",
        "        try:\n",
        "          leftEndpoint=convoluteShort(img,(30,30))\n",
        "          horizontal=[leftEndpoint]\n",
        "          vertical=[leftEndpoint]\n",
        "          while(len(horizontal)<10):\n",
        "            horizontal.append(nextHorizontalShort(img,horizontal[-1][0],horizontal[-1][1]))\n",
        "          while(len(vertical)<8):\n",
        "            vertical.append(nextVerticalShort(img,vertical[-1][0],vertical[-1][1]))\n",
        "          done=True\n",
        "          marked=timg\n",
        "          break\n",
        "        except:\n",
        "          if ii==0:\n",
        "            break\n",
        "      if done :\n",
        "        break\n",
        "  # print(done)\n",
        "  if not done:\n",
        "    raise \"not good image\"\n",
        "  else:\n",
        "    return horizontal,vertical,marked"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(50,50)\n",
        "num_classes=3"
      ],
      "metadata": {
        "id": "ffop9zFzft2N"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "ApCo7dU2uIKL"
      },
      "outputs": [],
      "source": [
        "def extractImg(img,x1,y1,x2,y2):\n",
        "  x1=x1-3\n",
        "  y1=y1-3\n",
        "  x2=x2+3\n",
        "  y2=y2+3\n",
        "  trimmed=img[y1:y2,x1:x2,np.newaxis]\n",
        "  trimmed=tf.image.resize([trimmed],input_shape)\n",
        "  return trimmed[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "YNsWb7RWLkx0"
      },
      "outputs": [],
      "source": [
        "def getSubImgs(marked):\n",
        "  horizontal,vertical,marked=giveHoriVer(marked)\n",
        "  allBlocks=getAllCells(horizontal,vertical,marked)\n",
        "  cells=marked.copy()\n",
        "  subImgs=[]\n",
        "  for lt,rb in allBlocks:\n",
        "    cv2.rectangle(cells,lt[::-1],rb[::-1],100,2)\n",
        "    subImgs.append(extractImg(marked,lt[1],lt[0],rb[1],rb[0]))\n",
        "  subImgs=tf.convert_to_tensor(subImgs)\n",
        "  return subImgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "1ACvTcAWSEdF"
      },
      "outputs": [],
      "source": [
        "kernelErode=np.ones((3,3),np.uint8)\n",
        "def readImgGray(filename):\n",
        "  imgGrid=cv2.imread(filename,cv2.IMREAD_GRAYSCALE)\n",
        "  imgGrid=cv2.threshold(imgGrid,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
        "  imgGrid=cv2.erode(imgGrid,kernelErode)\n",
        "  imgGrid=cv2.resize(imgGrid,(500,600),interpolation=cv2.INTER_AREA)\n",
        "  return imgGrid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "Xqpv-ATJgVkC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer,Flatten,Dropout,Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
        "from tensorflow.keras import layers, models, Model, optimizers\n",
        "from sklearn.model_selection import train_test_split as tts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "rozsI1hHZ9TF"
      },
      "outputs": [],
      "source": [
        "cellStates=['EMPTY','PRESENT','ABSENT']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def createData(imgName,stt):\n",
        "  subImgs=[]\n",
        "  states=[]\n",
        "  assert len(imgName)==len(stt)\n",
        "  for f,s in zip(imgName,stt):\n",
        "    si=getSubImgs(readImgGray(f))\n",
        "    sos=tf.constant(si.shape[0]*[s],tf.uint8)\n",
        "    subImgs.extend(si)\n",
        "    states.extend(sos)\n",
        "  return subImgs,states"
      ],
      "metadata": {
        "id": "I-kuNyyHlM8W"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subImgs,states=createData([\"grid.png\",\"handA.png\",\"handP.png\",\"excel.png\",\"excelA.png\",\"priyaA.jpeg\",\"priyaP.jpeg\"],[0,2,1,1,2,2,1])"
      ],
      "metadata": {
        "id": "coMpEWb6mD6O"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer,Conv2D,BatchNormalization,Activation,AveragePooling2D,Dense,MaxPooling2D"
      ],
      "metadata": {
        "id": "RyqQQAMNdwRg"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(X, num_filters: int, stride: int = 1, kernel_size: int = 3,\n",
        "                   activation: str = 'relu', bn: bool = True, conv_first: bool = True):\n",
        "    conv_layer = Conv2D(num_filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        strides=stride,\n",
        "                        padding='same')\n",
        "    # X = input\n",
        "    if conv_first:\n",
        "        X = conv_layer(X)\n",
        "        if bn:\n",
        "            X = BatchNormalization()(X)\n",
        "        if activation is not None:\n",
        "            X = Activation(activation)(X)\n",
        "            X = Dropout(0.2)(X)\n",
        "    else:\n",
        "        if bn:\n",
        "            X = BatchNormalization()(X)\n",
        "        if activation is not None:\n",
        "            X = Activation(activation)(X)\n",
        "        X = conv_layer(X)\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "DseIha-3dlYI"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_filters_in = 25\n",
        "num_res_block=2\n",
        "inputs = keras.Input(shape=input_shape+(1,))\n",
        "X=Conv2D(num_filters_in,kernel_size=3,name=\"first_Conv\")(inputs)\n",
        "X=BatchNormalization()(X)\n",
        "X=Activation('relu')(X)\n",
        "X=MaxPooling2D()(X)\n",
        "# ResNet V2 performs Conv2D on X before spiting into two path\n",
        "X = residual_block(X=X, num_filters=num_filters_in, conv_first=False)\n",
        "\n",
        "# Building stack of residual units\n",
        "for stage in range(2):\n",
        "    for unit_res_block in range(num_res_block):\n",
        "        activation = 'relu'\n",
        "        bn = True\n",
        "        stride = 1\n",
        "        # First layer and first stage\n",
        "        if stage == 0:\n",
        "            num_filters_out = num_filters_in * 4\n",
        "            if unit_res_block == 0:\n",
        "                activation = None\n",
        "                bn = False\n",
        "            # First layer but not first stage\n",
        "        else:\n",
        "            num_filters_out = num_filters_in * 2\n",
        "            if unit_res_block == 0:\n",
        "                stride = 2\n",
        "\n",
        "        # bottleneck residual unit\n",
        "        y = residual_block(X,\n",
        "                           num_filters=num_filters_in,\n",
        "                           kernel_size=1,\n",
        "                           stride=stride,\n",
        "                           activation=activation,\n",
        "                           bn=bn,\n",
        "                           conv_first=False)\n",
        "        y = residual_block(y,\n",
        "                           num_filters=num_filters_in,\n",
        "                           conv_first=False)\n",
        "        y = residual_block(y,\n",
        "                           num_filters=num_filters_out,\n",
        "                           kernel_size=1,\n",
        "                           conv_first=False)\n",
        "        if unit_res_block == 0:\n",
        "            # linear projection residual shortcut connection to match\n",
        "            # changed dims\n",
        "            X = residual_block(X=X,\n",
        "                               num_filters=num_filters_out,\n",
        "                               kernel_size=1,\n",
        "                               stride=stride,\n",
        "                               activation=None,\n",
        "                               bn=False)\n",
        "        X = tf.keras.layers.add([X, y])\n",
        "    num_filters_in = num_filters_out\n",
        "X = BatchNormalization()(X)\n",
        "X = Activation('relu')(X)\n",
        "X = AveragePooling2D()(X)\n",
        "y = Flatten()(X)\n",
        "y = Dense(512, activation='relu')(y)\n",
        "y = BatchNormalization()(y)\n",
        "y = Dropout(0.5)(y)\n",
        "# y = Dense(512, activation='relu')(y)\n",
        "# y = BatchNormalization()(y)\n",
        "# y = Dropout(0.5)(y)\n",
        "outputs = Dense(num_classes,\n",
        "                activation='softmax')(y)\n"
      ],
      "metadata": {
        "id": "kGIEC53PmcyI"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "90t_CIfJ3lO9"
      },
      "outputs": [],
      "source": [
        "def giveModel():\n",
        "  return tf.keras.models.load_model(\"resConv4GridModel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "ukKwtrpfApHh"
      },
      "outputs": [],
      "source": [
        "# lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n",
        "# checkpoint = ModelCheckpoint('vgg16_finetune.h15', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "_PTqeU5Oaccz"
      },
      "outputs": [],
      "source": [
        "def createDataSet(X,y,is_training=False):\n",
        "  ds=tf.data.Dataset.from_tensor_slices((X,y))\n",
        "  ds=ds.batch(32).prefetch(32)\n",
        "  if is_training:\n",
        "    ds=ds.shuffle(32)\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "CsaicnN7fNDw"
      },
      "outputs": [],
      "source": [
        "# X=np.array(subImgs)\n",
        "# y=np.array(states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "iLqo64-8glAx"
      },
      "outputs": [],
      "source": [
        "# X_train,X_test,y_train,y_test=tts(X,y,test_size=0.10,random_state=42,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "xaXsJO7-jepE"
      },
      "outputs": [],
      "source": [
        "# train_ds=createDataSet(X_train,y_train,True)\n",
        "# val_ds=createDataSet(X_test,y_test,True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Attendance_model=giveModel()\n",
        "# keras.utils.plot_model(Attendance_model)\n",
        "# Attendance_model.summary()"
      ],
      "metadata": {
        "id": "z6pJi-lFkkZq"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "dKakxFqSA01b"
      },
      "outputs": [],
      "source": [
        "# learning_rate= 5e-5\n",
        "# Attendance_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizers.Adam(learning_rate=learning_rate), metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "rQPtSkh8BLlS"
      },
      "outputs": [],
      "source": [
        "# with tf.device(\"/GPU:0\"):\n",
        "# history = Attendance_model.fit(train_ds, epochs=50,validation_data=val_ds,verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "SeuM3VNOnQvp"
      },
      "outputs": [],
      "source": [
        "# Attendance_model.evaluate(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def imgWithLabel(img,model,labels):\n",
        "  pred=tf.argmax(model.predict(np.array([img])),axis=1)[0].numpy()\n",
        "  try:\n",
        "    img=tf.image.grayscale_to_rgb(img)\n",
        "    image = cv2.putText(img.numpy(), labels[pred][0], (20,20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0),  2, cv2.LINE_AA)\n",
        "  except:\n",
        "    image = cv2.putText(img, labels[pred][0], (20,20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0),  2, cv2.LINE_AA)\n",
        "  return image"
      ],
      "metadata": {
        "id": "2wJCtjMHtSW8"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "63FTFzfA2QSQ"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subImgs,states=createData([\"grid.png\",\"priyaA.jpeg\",\"priyaP.jpeg\"],[0,2,1])\n",
        "sz=5\n",
        "subImgs=tf.random.shuffle(subImgs)\n",
        "for i in subImgs[:sz]:\n",
        "  display(show(imgWithLabel(i,Attendance_model,cellStates)))"
      ],
      "metadata": {
        "id": "hivVfj4IuZAb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "7d70e085-41e3-4859-eb51-f33b152f3e32"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=50x50 at 0x7F2B64118E10>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=50x50 at 0x7F2B64118E10>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=50x50 at 0x7F2B66275510>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAIAAACRXR/mAAABb0lEQVR4nO2Wv4qDQBCHZ/1DQBD2NH3K1F5jkXsASZPSp7WzUZQ8gElr5aFgMJFgvGIvXnPc7eByZzEfgjOs/PhYl1EYn3Rd5/s+PHEc53w+j3IAIK5fCYLAAKWMo5ocTU2Maow4jkXV933bttPC/X7PsqwsS7mcN3Gb0uZQ1zXjnE9927bDMIiaMWbbtqZJbWfT1KLg/GW+1uVyYfNTAABgOlNqAhd6thaqZXieJ6rH41EURdd1otV1fbvdrlYrmZTjcSq/mRCe94pyOp1OrKoq0dxut8PhkOe5aDnnURRtNhuZoPXa/fmBqnqX1wrD0HDdz8Tr9WoYX9NV0zTO+bQ6h3EEAESOaZo05TGQFgbSwkBaGBTPLSbxAyEz2/5ht2TU1WihhrvMw8peoqrPjmChR560MJAWBtLCQFoYSAsDaWEgLQykhYG0MJAWBtLCQFoYFqrF9vu9qIZhSJKkaRrRmqa52+0sy/p7pzRNPwDL48a/PJra2QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=50x50 at 0x7F2B642239D0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=50x50 at 0x7F2AE9313E10>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAIAAACRXR/mAAABMklEQVR4nO2ZO26EMBBAx2CBhChJnYtxBB+DQyCORE1Fh2i3QAJc2AqkcPBSRFlPdrKhmCckBg2Mnj8aF8B+UFUVnCjL0hizhwGAuB6ilJJAyr7T1IloylAjh2Fw0TRN58S6ruM4xnEcVufd3Xy1Z5jnWUTR14Qdu+SOTz1k2z6OTwKH8XO1TTxfBQAA/HhoCl50b11USxZF4SKttdbaJ9I0zfNciKBFud18+E2HKIo3lNOyLPfu9qftFIVS6hWL+Isey10eA2thYC0MrIWBuG+FnFUhve0fZitEnUYL1dxDXiZbRKpjx3HRLc9aGFgLA2thYC0MrIWBtTCwFgbWwsBaGFgLA2thYC0Msq5rF7Vte070fd80TfCvKEq6rhNZlrkHa6211ueklEmSvN4JAIwxn3NBISsopK9oAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attendance_model.save(\"resConv4GridModel\")"
      ],
      "metadata": {
        "id": "mbKKQN6rKwn1"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-T-qezuKOrxQ"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !du -h resConv4GridModel"
      ],
      "metadata": {
        "id": "YxlUjxIcP3d2"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r resConv4GridModel.zip resConv4GridModel"
      ],
      "metadata": {
        "id": "7QUbk_HuQQLK"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keras.utils.plot_model(model)"
      ],
      "metadata": {
        "id": "-OPO9MPKQemv"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tLE4HjsxRlNw"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r resConv4GridModel resConv4GridModel"
      ],
      "metadata": {
        "id": "ZVPzmIKsvtKZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3396f8b5-4aac-48eb-f2ad-6bdaf556c3a7"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: resConv4GridModel/ (stored 0%)\n",
            "updating: resConv4GridModel/saved_model.pb (deflated 91%)\n",
            "updating: resConv4GridModel/assets/ (stored 0%)\n",
            "updating: resConv4GridModel/keras_metadata.pb (deflated 95%)\n",
            "updating: resConv4GridModel/variables/ (stored 0%)\n",
            "updating: resConv4GridModel/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "updating: resConv4GridModel/variables/variables.index (deflated 77%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2aoRDDxvOMjr"
      },
      "execution_count": 120,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Blocks_training_gpu_by_resNet_optimized_by_threshold.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}